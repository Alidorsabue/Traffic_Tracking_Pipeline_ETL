#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de diagnostic pour v√©rifier pourquoi les tables sont vides.
V√©rifie chaque √©tape de la cha√Æne de traitement des donn√©es.
"""

import sys
import os
import locale

# Forcer l'encodage UTF-8 pour √©viter les probl√®mes d'encodage
if sys.platform == 'win32':
    # Sur Windows, essayer de d√©finir l'encodage UTF-8
    try:
        if sys.stdout.encoding != 'utf-8':
            sys.stdout.reconfigure(encoding='utf-8')
        if sys.stderr.encoding != 'utf-8':
            sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

# S'assurer que le chemin est encod√© correctement
script_dir = os.path.dirname(os.path.abspath(__file__))
if isinstance(script_dir, bytes):
    script_dir = script_dir.decode('utf-8')

sys.path.insert(0, os.path.join(script_dir, '..'))

from src.Script_ETL import get_db_connection
import pandas as pd
from datetime import datetime, timedelta

# Alternative: Connexion directe si get_db_connection √©choue
def get_db_connection_direct():
    """Connexion directe √† PostgreSQL pour √©viter les probl√®mes d'encodage."""
    import psycopg2
    
    # Utiliser les valeurs directement (√©viter os.getenv qui peut avoir des probl√®mes d'encodage)
    try:
        conn = psycopg2.connect(
            host='africaits.com',
            port=5432,
            database='Traffic_Tracking',
            user='Alidorsabue',
            password='Virgi@1996',
            client_encoding='UTF8',
            connect_timeout=10
        )
        return conn
    except Exception as e:
        print(f"‚ùå Erreur de connexion directe: {e}")
        raise

# Alternative: Connexion directe si get_db_connection √©choue
def get_db_connection_direct():
    """Connexion directe √† PostgreSQL pour √©viter les probl√®mes d'encodage."""
    import psycopg2
    
    # Utiliser les valeurs directement (√©viter os.getenv qui peut avoir des probl√®mes d'encodage)
    # Ces valeurs peuvent √™tre modifi√©es si n√©cessaire
    try:
        conn = psycopg2.connect(
            host='africaits.com',
            port=5432,
            database='Traffic_Tracking',
            user='Alidorsabue',
            password='Virgi@1996',
            client_encoding='UTF8',
            connect_timeout=10
        )
        return conn
    except Exception as e:
        print(f"‚ùå Erreur de connexion directe: {e}")
        raise

def check_table_data(table_name, query=None, use_direct=False):
    """V√©rifie si une table contient des donn√©es."""
    conn = None
    try:
        # Essayer d'abord get_db_connection, puis connexion directe si √©chec
        if use_direct:
            conn = get_db_connection_direct()
        else:
            try:
                conn = get_db_connection()
            except (UnicodeDecodeError, UnicodeError) as e:
                print(f"[WARNING] Probl√®me d'encodage avec get_db_connection(), utilisation de la connexion directe...")
                conn = get_db_connection_direct()
    except Exception as e:
        print(f"[ERROR] ERREUR lors de la connexion √† la base de donn√©es: {e}")
        return {
            'exists': False,
            'error': str(e),
            'has_data': False,
            'connection_error': True
        }
    
    try:
        if query:
            df = pd.read_sql(query, conn)
        else:
            df = pd.read_sql(f"SELECT * FROM {table_name} LIMIT 10", conn)
        
        total_count = pd.read_sql(f"SELECT COUNT(*) as count FROM {table_name}", conn)['count'].iloc[0]
        
        return {
            'exists': True,
            'total_rows': int(total_count),
            'sample_data': df,
            'has_data': total_count > 0
        }
    except Exception as e:
        return {
            'exists': False,
            'error': str(e),
            'has_data': False
        }
    finally:
        conn.close()

def diagnostic_complete():
    """Effectue un diagnostic complet de toutes les tables."""
    print("=" * 80)
    print("DIAGNOSTIC DES TABLES - TRAFFIC TRACKING PIPELINE")
    print("=" * 80)
    print(f"Date du diagnostic: {datetime.now()}\n")
    
    # Test de connexion d'abord
    print("[INFO] Test de connexion √† la base de donn√©es...")
    try:
        test_conn = get_db_connection()
        test_conn.close()
        print("[SUCCESS] Connexion r√©ussie avec get_db_connection()\n")
        use_direct = False
    except (UnicodeDecodeError, UnicodeError) as e:
        print(f"[WARNING] Probl√®me d'encodage d√©tect√©, utilisation de la connexion directe...")
        try:
            test_conn = get_db_connection_direct()
            test_conn.close()
            print("[SUCCESS] Connexion r√©ussie avec connexion directe\n")
            use_direct = True
        except Exception as e2:
            print(f"[ERROR] Impossible de se connecter √† la base de donn√©es: {e2}")
            print("\nV√©rifier:")
            print("  1. Que le serveur PostgreSQL est accessible (africaits.com:5432)")
            print("  2. Que les credentials sont corrects")
            print("  3. Que le pare-feu permet la connexion")
            return None
    except Exception as e:
        print(f"[ERROR] Erreur de connexion: {e}")
        return None
    
    results = {}
    
    # 1. V√©rifier gps_points (SOURCE DE DONN√âES)
    print("\n[1] V√âRIFICATION DE gps_points (SOURCE)")
    print("-" * 80)
    query_recent = """
        SELECT COUNT(*) as count,
               MIN(timestamp) as oldest,
               MAX(timestamp) as newest
        FROM gps_points
    """
    gps_check = check_table_data('gps_points', query_recent, use_direct=use_direct)
    results['gps_points'] = gps_check
    
    if gps_check.get('exists'):
        print(f"[SUCCESS] Table gps_points existe")
        if gps_check['has_data']:
            print(f"[SUCCESS] {gps_check['total_rows']} lignes au total")
            gps_details = gps_check['sample_data']
            if not gps_details.empty and 'oldest' in gps_details.columns:
                print(f"   Plus ancienne donn√©e: {gps_details['oldest'].iloc[0]}")
                print(f"   Plus r√©cente donn√©e: {gps_details['newest'].iloc[0]}")
        else:
            print(f"[ERROR] Table gps_points est VIDE")
            print(f"   [WARNING] PROBL√àME: L'app mobile n'envoie pas de donn√©es ou la connexion DB ne fonctionne pas")
    else:
        print(f"[ERROR] Table gps_points n'existe pas: {gps_check.get('error')}")
    
    # 2. V√©rifier mapmatching_cache
    print("\n[2] V√âRIFICATION DE mapmatching_cache")
    print("-" * 80)
    query_cache_recent = """
        SELECT COUNT(*) as count,
               MIN(processed_at) as oldest_processed,
               MAX(processed_at) as newest_processed,
               COUNT(CASE WHEN edge_u IS NOT NULL THEN 1 END) as matched_count
        FROM mapmatching_cache
        WHERE processed_at > NOW() - INTERVAL '2 hours'
    """
    cache_check = check_table_data('mapmatching_cache', query_cache_recent, use_direct=use_direct)
    results['mapmatching_cache'] = cache_check
    
    if cache_check.get('exists'):
        print(f"[SUCCESS] Table mapmatching_cache existe")
        if cache_check['has_data']:
            cache_details = cache_check['sample_data']
            if not cache_details.empty:
                total_recent = cache_details['count'].iloc[0] if 'count' in cache_details.columns else 0
                matched = cache_details['matched_count'].iloc[0] if 'matched_count' in cache_details.columns else 0
                print(f"[SUCCESS] {total_recent} entr√©es dans les 2 derni√®res heures")
                print(f"   {matched} points match√©s ({matched/total_recent*100:.1f}%)" if total_recent > 0 else "   0% match√©s")
                if 'newest_processed' in cache_details.columns:
                    print(f"   Derni√®re mise √† jour: {cache_details['newest_processed'].iloc[0]}")
        else:
            print(f"[ERROR] Table mapmatching_cache est VIDE ou aucune donn√©e r√©cente")
            print(f"   [WARNING] PROBL√àME: Le DAG 'mapmatching_cache_hourly' ne s'ex√©cute pas ou √©choue")
            print(f"   Solution: V√©rifier que le DAG mapmatching_cache_hourly s'ex√©cute toutes les heures")
    else:
        print(f"[ERROR] Table mapmatching_cache n'existe pas: {cache_check.get('error')}")
    
    # 3. V√©rifier edge_agg
    print("\n[3] V√âRIFICATION DE edge_agg")
    print("-" * 80)
    query_edge_recent = """
        SELECT COUNT(*) as count,
               MIN(ts) as oldest,
               MAX(ts) as newest
        FROM edge_agg
        WHERE ts > NOW() - INTERVAL '24 hours'
    """
    edge_check = check_table_data('edge_agg', query_edge_recent, use_direct=use_direct)
    results['edge_agg'] = edge_check
    
    if edge_check.get('exists'):
        print(f"[SUCCESS] Table edge_agg existe")
        if edge_check['has_data']:
            edge_details = edge_check['sample_data']
            if not edge_details.empty:
                recent_count = edge_details['count'].iloc[0] if 'count' in edge_details.columns else 0
                print(f"[SUCCESS] {recent_count} lignes dans les 24 derni√®res heures")
                total_edge = check_table_data('edge_agg', "SELECT COUNT(*) as count FROM edge_agg")['total_rows']
                print(f"   Total: {total_edge} lignes")
        else:
            print(f"[ERROR] Table edge_agg est VIDE ou aucune donn√©e r√©cente")
            print(f"   [WARNING] PROBL√àME: Le DAG 'traffic_advanced_analysis' ne peut pas charger de donn√©es")
            print(f"   Causes possibles:")
            print(f"     - mapmatching_cache est vide")
            print(f"     - Les donn√©es GPS ne peuvent pas √™tre match√©es √† des routes")
            print(f"     - Le DAG traffic_advanced_analysis √©choue")
    else:
        print(f"[ERROR] Table edge_agg n'existe pas: {edge_check.get('error')}")
    
    # 4. V√©rifier predictions
    print("\n[4] V√âRIFICATION DE predictions")
    print("-" * 80)
    query_pred_recent = """
        SELECT COUNT(*) as count,
               MIN(ts) as oldest,
               MAX(ts) as newest
        FROM predictions
        WHERE ts > NOW() - INTERVAL '24 hours'
    """
    pred_check = check_table_data('predictions', query_pred_recent, use_direct=use_direct)
    results['predictions'] = pred_check
    
    if pred_check.get('exists'):
        print(f"[SUCCESS] Table predictions existe")
        if pred_check['has_data']:
            pred_details = pred_check['sample_data']
            if not pred_details.empty:
                recent_count = pred_details['count'].iloc[0] if 'count' in pred_details.columns else 0
                print(f"[SUCCESS] {recent_count} pr√©dictions dans les 24 derni√®res heures")
        else:
            print(f"[ERROR] Table predictions est VIDE")
            print(f"   [WARNING] PROBL√àME: Le mod√®le ML ne peut pas g√©n√©rer de pr√©dictions")
            print(f"   Causes possibles:")
            print(f"     - edge_agg est vide (pas de donn√©es pour entra√Æner/pr√©dire)")
            print(f"     - Le mod√®le ML √©choue lors de l'entra√Ænement ou de la pr√©diction")
    else:
        print(f"[ERROR] Table predictions n'existe pas: {pred_check.get('error')}")
    
    # 5. V√©rifier edge_hourly_baseline
    print("\n[5] V√âRIFICATION DE edge_hourly_baseline")
    print("-" * 80)
    baseline_check = check_table_data('edge_hourly_baseline', "SELECT COUNT(*) as count FROM edge_hourly_baseline", use_direct=use_direct)
    results['edge_hourly_baseline'] = baseline_check
    
    if baseline_check.get('exists'):
        print(f"[SUCCESS] Table edge_hourly_baseline existe")
        if baseline_check['has_data']:
            print(f"[SUCCESS] {baseline_check['total_rows']} lignes de baseline")
            query_baseline_details = """
                SELECT COUNT(DISTINCT edge_u || '-' || edge_v) as unique_edges,
                       COUNT(DISTINCT hour) as unique_hours
                FROM edge_hourly_baseline
            """
            try:
                conn = get_db_connection()
                details = pd.read_sql(query_baseline_details, conn)
                conn.close()
                if not details.empty:
                    print(f"   {details['unique_edges'].iloc[0]} tron√ßons uniques")
                    print(f"   {details['unique_hours'].iloc[0]} heures couvertes")
            except:
                pass
        else:
            print(f"‚ùå Table edge_hourly_baseline est VIDE")
            print(f"   ‚ö†Ô∏è  PROBL√àME: Le DAG 'compute_baseline_daily' ne peut pas calculer la baseline")
            print(f"   Causes possibles:")
            print(f"     - edge_agg est vide (pas de donn√©es historiques)")
            print(f"     - Le DAG compute_baseline_daily ne s'ex√©cute pas ou √©choue")
    else:
        print(f"‚ùå Table edge_hourly_baseline n'existe pas: {baseline_check.get('error')}")
    
    # R√©sum√© et recommandations
    print("\n" + "=" * 80)
    print("R√âSUM√â ET RECOMMANDATIONS")
    print("=" * 80)
    
    issues = []
    
    if not results.get('gps_points', {}).get('has_data'):
        issues.append("üî¥ CRITIQUE: gps_points est vide - V√©rifier que l'app mobile envoie des donn√©es")
        issues.append("   Action: V√©rifier la connexion √† la base de donn√©es depuis l'app mobile")
    
    if not results.get('mapmatching_cache', {}).get('has_data'):
        issues.append("üî¥ CRITIQUE: mapmatching_cache est vide - Le DAG mapmatching_cache_hourly doit s'ex√©cuter")
        issues.append("   Action: V√©rifier dans Airflow que le DAG 'mapmatching_cache_hourly' s'ex√©cute toutes les heures")
    
    if not results.get('edge_agg', {}).get('has_data'):
        issues.append("üü° WARNING: edge_agg est vide - D√©pend de mapmatching_cache")
        issues.append("   Action: R√©soudre d'abord le probl√®me de mapmatching_cache")
    
    if not results.get('predictions', {}).get('has_data'):
        issues.append("üü° WARNING: predictions est vide - D√©pend de edge_agg")
        issues.append("   Action: R√©soudre d'abord le probl√®me de edge_agg")
    
    if not results.get('edge_hourly_baseline', {}).get('has_data'):
        issues.append("üü° WARNING: edge_hourly_baseline est vide - D√©pend de edge_agg")
        issues.append("   Action: R√©soudre d'abord le probl√®me de edge_agg, puis ex√©cuter compute_baseline_daily")
    
    if issues:
        print("\nProbl√®mes d√©tect√©s:")
        for issue in issues:
            print(f"   {issue}")
    else:
        print("\n‚úÖ Toutes les tables contiennent des donn√©es!")
    
    print("\n" + "=" * 80)
    return results

if __name__ == "__main__":
    diagnostic_complete()

