# dags/Mapmatching_DAG.py
"""
DAG pour effectuer le map matching des donn√©es GPS r√©centes.
S'ex√©cute une fois par heure et stocke les r√©sultats dans mapmatching_cache pour r√©utilisation.
Cela √©vite de bloquer le pipeline principal avec le map matching √† chaque ex√©cution.
"""

from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
import sys
sys.path.insert(0, '/opt/airflow')

default_args = {
    'owner': 'congestion_team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=10),
    'email_on_failure': False,
    'email_on_retry': False,
}

def mapmatching_cache_task(**context):
    """
    Effectue le map matching sur les donn√©es GPS r√©centes et stocke les r√©sultats dans mapmatching_cache.
    Cette t√¢che s'ex√©cute toutes les heures pour maintenir un cache √† jour.
    Version am√©lior√©e avec meilleure gestion des erreurs et logging d√©taill√©.
    """
    import time
    start_time = time.time()
    
    try:
        # Import lazy pour √©viter le timeout au chargement du DAG
        from src.mapmatching import effectuer_mapmatching, telecharger_reseau
        from src.Script_ETL import extract_recent_data, clean_data, get_db_connection
        import pandas as pd
        
        print("=" * 80)
        print("üîÑ D√âBUT DU MAP MATCHING POUR LE CACHE")
        print("=" * 80)
        print(f"Timestamp: {datetime.now()}\n")
        
        # √âTAPE 1: Extraction des donn√©es GPS depuis la table gps_points
        # IMPORTANT: Cette √©tape lit les donn√©es GPS collect√©es par l'app mobile
        print("[√âTAPE 1/5] üì• Extraction des donn√©es GPS depuis gps_points (app mobile)...")
        try:
            # extract_recent_data() lit depuis la table gps_points:
            # SELECT driver_id, latitude, longitude, speed, timestamp FROM gps_points
            df = extract_recent_data()
            
            if df is None:
                print("‚ùå ERREUR: extract_recent_data() a retourn√© None")
                return "extraction_error"
            
            if df.empty:
                print("‚ö†Ô∏è Aucune donn√©e GPS r√©cente √† traiter")
                print("   V√©rifier que la table gps_points contient des donn√©es r√©centes")
                print("   V√©rifier que l'app mobile envoie bien les donn√©es √† la base de donn√©es")
                return "no_data"
            
            print(f"‚úÖ {len(df)} points GPS extraits depuis gps_points")
            print(f"   Colonnes: {list(df.columns)}")
            if not df.empty:
                print(f"   Exemple: driver_id={df['driver_id'].iloc[0]}, lat={df['latitude'].iloc[0]:.6f}, lon={df['longitude'].iloc[0]:.6f}")
            elapsed = time.time() - start_time
            print(f"   Temps √©coul√©: {elapsed:.2f}s\n")
            
        except Exception as e:
            print(f"‚ùå ERREUR lors de l'extraction des donn√©es GPS: {e}")
            import traceback
            traceback.print_exc()
            return "extraction_error"
        
        # √âTAPE 2: Nettoyage des donn√©es
        print("[√âTAPE 2/5] üßπ Nettoyage des donn√©es...")
        try:
            df_clean = clean_data(df)
            
            if df_clean.empty:
                print("‚ö†Ô∏è Aucune donn√©e valide apr√®s nettoyage")
                print("   Les donn√©es GPS ont peut-√™tre √©t√© filtr√©es (vitesses aberrantes, doublons)")
                return "no_valid_data"
            
            print(f"‚úÖ {len(df_clean)} points GPS valides apr√®s nettoyage")
            print(f"   {len(df) - len(df_clean)} points filtr√©s")
            elapsed = time.time() - start_time
            print(f"   Temps √©coul√©: {elapsed:.2f}s\n")
            
        except Exception as e:
            print(f"‚ùå ERREUR lors du nettoyage: {e}")
            import traceback
            traceback.print_exc()
            return "cleaning_error"
        
        # √âTAPE 3: Pr√©paration des donn√©es pour mapmatching
        print("[√âTAPE 3/5] üîß Pr√©paration des donn√©es pour mapmatching...")
        try:
            # OPTIMISATION: R√©duire le nombre de points pour √©viter les timeouts
            # 100 points peuvent prendre 28 minutes, r√©duisons √† 50
            max_points_to_process = 50
            
            if len(df_clean) > max_points_to_process:
                df_limited = df_clean.head(max_points_to_process)
                print(f"‚ö†Ô∏è Mapmatching limit√© √† {max_points_to_process} points (sur {len(df_clean)} disponibles)")
            else:
                df_limited = df_clean
                print(f"‚úÖ {len(df_limited)} points √† traiter")
            
            # V√©rifier les coordonn√©es
            invalid_coords = df_limited[
                (df_limited['latitude'].isna()) | 
                (df_limited['longitude'].isna()) |
                (df_limited['latitude'] < -90) | (df_limited['latitude'] > 90) |
                (df_limited['longitude'] < -180) | (df_limited['longitude'] > 180)
            ]
            if not invalid_coords.empty:
                print(f"‚ö†Ô∏è {len(invalid_coords)} points avec coordonn√©es invalides seront ignor√©s")
                df_limited = df_limited.drop(invalid_coords.index)
            
            if df_limited.empty:
                print("‚ùå Aucun point valide apr√®s v√©rification des coordonn√©es")
                return "no_valid_coords"
            
            elapsed = time.time() - start_time
            print(f"   Temps √©coul√©: {elapsed:.2f}s\n")
            
        except Exception as e:
            print(f"‚ùå ERREUR lors de la pr√©paration: {e}")
            import traceback
            traceback.print_exc()
            return "preparation_error"
        
        # √âTAPE 4: Ex√©cution du map matching
        # IMPORTANT: Cette √©tape associe les points GPS collect√©s (gps_points) aux routes (OpenStreetMap)
        print("[√âTAPE 4/5] üó∫Ô∏è Ex√©cution du map matching...")
        print("   FLUX: Points GPS (gps_points) ‚Üê App mobile")
        print("         R√©seau routier (OSM) ‚Üê OpenStreetMap (t√©l√©charg√©)")
        print("         Association ‚Üê Trouver la route la plus proche de chaque point GPS")
        print("   Cette √©tape peut prendre plusieurs minutes...")
        mapmatching_start = time.time()
        
        try:
            # effectuer_mapmatching() va:
            # 1. Prendre les points GPS de df_limited (qui viennent de gps_points)
            # 2. T√©l√©charger le r√©seau routier depuis OpenStreetMap pour Kinshasa
            # 3. Associer chaque point GPS au tron√ßon de route le plus proche
            df_matched = effectuer_mapmatching(
                df_limited,  # Points GPS collect√©s depuis gps_points
                max_points=max_points_to_process, 
                max_distance=50,
                place="Kinshasa, Democratic Republic of the Congo"  # Lieu pour t√©l√©charger le r√©seau OSM
            )
            
            mapmatching_elapsed = time.time() - mapmatching_start
            print(f"‚úÖ Map matching termin√© en {mapmatching_elapsed:.2f}s")
            
            if df_matched is None:
                print("‚ùå ERREUR: effectuer_mapmatching() a retourn√© None")
                return "mapmatching_returned_none"
            
            if df_matched.empty:
                print("‚ö†Ô∏è Aucun r√©sultat apr√®s map matching")
                print("   Cela peut arriver si:")
                print("   - Le r√©seau routier n'a pas pu √™tre t√©l√©charg√©")
                print("   - Les points GPS sont trop √©loign√©s des routes (> 50m)")
                return "no_match_result"
            
            # Compter les points match√©s
            if 'edge_u' in df_matched.columns:
                matched_count = df_matched['edge_u'].notna().sum()
                match_rate = (matched_count / len(df_matched) * 100) if len(df_matched) > 0 else 0
                print(f"‚úÖ {matched_count}/{len(df_matched)} points match√©s ({match_rate:.1f}%)")
                
                if matched_count == 0:
                    print("‚ö†Ô∏è ATTENTION: Aucun point n'a √©t√© match√© √† une route")
                    print("   Les donn√©es seront quand m√™me sauvegard√©es pour r√©f√©rence")
            else:
                print("‚ö†Ô∏è Colonne 'edge_u' manquante dans le r√©sultat")
                matched_count = 0
            
            elapsed = time.time() - start_time
            print(f"   Temps √©coul√© total: {elapsed:.2f}s\n")
            
        except Exception as e:
            mapmatching_elapsed = time.time() - mapmatching_start
            print(f"‚ùå ERREUR lors du map matching apr√®s {mapmatching_elapsed:.2f}s: {e}")
            import traceback
            traceback.print_exc()
            print("\nCauses possibles:")
            print("   - Probl√®me de connexion internet (t√©l√©chargement r√©seau routier)")
            print("   - Timeout lors du t√©l√©chargement du r√©seau routier")
            print("   - Erreur dans OSMnx ou GeoPandas")
            return "mapmatching_error"
        
        # √âTAPE 5: Stockage dans mapmatching_cache
        print("[√âTAPE 5/5] üíæ Stockage des r√©sultats dans mapmatching_cache...")
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # Pr√©parer les donn√©es pour insertion
            required_cols = ['driver_id', 'latitude', 'longitude', 'speed', 'timestamp']
            optional_cols = ['edge_u', 'edge_v', 'osmid', 'road_name', 'distance_to_road']
            
            # V√©rifier que les colonnes requises existent
            missing_cols = set(required_cols) - set(df_matched.columns)
            if missing_cols:
                print(f"‚ùå Colonnes manquantes: {missing_cols}")
                cursor.close()
                conn.close()
                return "missing_columns"
            
            # S√©lectionner les colonnes √† ins√©rer
            cols_to_insert = required_cols.copy()
            for col in optional_cols:
                if col in df_matched.columns:
                    cols_to_insert.append(col)
            
            df_to_insert = df_matched[cols_to_insert].copy()
            
            # Ajouter une colonne processed_at
            df_to_insert['processed_at'] = datetime.now()
            
            # Supprimer les anciennes donn√©es (derni√®res 2 heures)
            delete_query = """
                DELETE FROM mapmatching_cache 
                WHERE processed_at > NOW() - INTERVAL '2 hours'
            """
            cursor.execute(delete_query)
            deleted_count = cursor.rowcount
            print(f"üóëÔ∏è {deleted_count} anciennes entr√©es supprim√©es du cache")
            
            # Pr√©parer les valeurs pour insertion
            values = []
            for _, row in df_to_insert.iterrows():
                try:
                    values.append((
                        str(row['driver_id']) if pd.notna(row['driver_id']) else None,
                        float(row['latitude']) if pd.notna(row['latitude']) else None,
                        float(row['longitude']) if pd.notna(row['longitude']) else None,
                        float(row['speed']) if pd.notna(row['speed']) else None,
                        row['timestamp'] if pd.notna(row['timestamp']) else datetime.now(),
                        int(row['edge_u']) if 'edge_u' in row and pd.notna(row.get('edge_u')) else None,
                        int(row['edge_v']) if 'edge_v' in row and pd.notna(row.get('edge_v')) else None,
                        int(row['osmid']) if 'osmid' in row and pd.notna(row.get('osmid')) else None,
                        str(row['road_name']) if 'road_name' in row and pd.notna(row.get('road_name')) else None,
                        float(row['distance_to_road']) if 'distance_to_road' in row and pd.notna(row.get('distance_to_road')) else None,
                        row['processed_at']
                    ))
                except Exception as e_row:
                    print(f"‚ö†Ô∏è Erreur lors de la pr√©paration d'une ligne: {e_row}")
                    continue
            
            if not values:
                print("‚ùå Aucune valeur valide √† ins√©rer")
                conn.rollback()
                cursor.close()
                conn.close()
                return "no_valid_values"
            
            # Ins√©rer les donn√©es
            insert_query = """
                INSERT INTO mapmatching_cache 
                (driver_id, latitude, longitude, speed, timestamp, edge_u, edge_v, osmid, road_name, distance_to_road, processed_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (driver_id, timestamp) DO UPDATE SET
                    edge_u = EXCLUDED.edge_u,
                    edge_v = EXCLUDED.edge_v,
                    osmid = EXCLUDED.osmid,
                    road_name = EXCLUDED.road_name,
                    distance_to_road = EXCLUDED.distance_to_road,
                    processed_at = EXCLUDED.processed_at
            """
            
            from psycopg2.extras import execute_values
            execute_values(cursor, insert_query, values, page_size=100)
            conn.commit()
            
            total_elapsed = time.time() - start_time
            print(f"‚úÖ {len(values)} entr√©es ajout√©es au cache mapmatching")
            print(f"‚úÖ T√¢che termin√©e avec succ√®s en {total_elapsed:.2f}s")
            print("=" * 80)
            
            cursor.close()
            conn.close()
            return "success"
            
        except Exception as e:
            if conn:
                conn.rollback()
            print(f"‚ùå Erreur lors de l'insertion dans mapmatching_cache: {e}")
            import traceback
            traceback.print_exc()
            return "insert_error"
        finally:
            if cursor:
                cursor.close()
            if conn:
                conn.close()
            
    except Exception as e:
        total_elapsed = time.time() - start_time
        print(f"‚ùå ERREUR CRITIQUE dans mapmatching_cache_task apr√®s {total_elapsed:.2f}s: {e}")
        import traceback
        traceback.print_exc()
        return "critical_error"

with DAG(
    'mapmatching_cache_hourly',
    default_args=default_args,
    description='Effectue le map matching toutes les heures et stocke les r√©sultats dans le cache',
    schedule_interval='0 * * * *',  # Toutes les heures √† minute 0
    catchup=False,
    tags=['mapmatching', 'cache', 'hourly'],
    max_active_runs=1  # Une seule ex√©cution √† la fois
) as dag:

    mapmatching_cache = PythonOperator(
        task_id='mapmatching_cache',
        python_callable=mapmatching_cache_task,
        execution_timeout=timedelta(minutes=45),  # Timeout augment√© √† 45 minutes (28 min observ√© + marge)
    )

    mapmatching_cache

